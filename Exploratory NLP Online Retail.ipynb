{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pylab as pl\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2, linewidth=120, suppress=True, edgeitems=4)\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 150)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "#pd.set_option('precision', 5)\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stopWords = stopwords.words('english') + list(string.punctuation)\n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('/Users/zacklarsen/Dropbox/Inference Analytics Team Folder/Zack Work')\n",
    "!ls *csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Load in dataset and clean up\n",
    "\n",
    "OR = pd.read_csv('OR.csv',dtype={'CustomerID': str})\n",
    "OR.drop('Unnamed: 0',axis=1,inplace=True) # Remove annoying index that excel creates\n",
    "OR['Date'] = pd.to_datetime(OR['Date']) # Convert date to datetime\n",
    "OR['Week'] = OR['Date'].dt.week # Obtain week number\n",
    "OR = OR[~OR['CustomerID'].isnull() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis on OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Week with highest number of StockCodes\n",
    "\n",
    "OR.groupby(['Week']).count().StockCode.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Most popular item per week\n",
    "\n",
    "SC = pd.DataFrame(OR.groupby(['Week','StockCode']).StockCode.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SCDF = SC.unstack(level=0,fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SCDF.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SC.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OR[OR['StockCode'] == '22086']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 1 Number of items per order\n",
    "IPO = pd.DataFrame(OR.groupby(['CustomerID','InvoiceNo'])['Quantity'].sum()).reset_index()\n",
    "\n",
    "## 2 Number of DISTINCT items per order\n",
    "DIPC = pd.DataFrame(OR.groupby(['CustomerID','InvoiceNo'])['Quantity'].count()).reset_index()\n",
    "\n",
    "## 3 Number of orders per customer\n",
    "OPC = pd.DataFrame(OR.groupby(['CustomerID'])['InvoiceNo'].count()).reset_index()\n",
    "\n",
    "## 4 Total amount per invoice\n",
    "TOT = pd.DataFrame(OR.groupby(['InvoiceNo'])['Total Amount'].sum())\n",
    "TOT.sort_values('Total Amount',ascending=False,inplace=True)\n",
    "## After inspection, it seems like any orders over $1,500 are outliers, so let's remove them\n",
    "TOT = TOT[TOT['Total Amount'] <1501]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=TOT[\"Total Amount\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(TOT[\"Total Amount\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.violinplot(TOT[\"Total Amount\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(IPO.Quantity);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.stripplot(x=\"CustomerID\", y=\"InvoiceNo\", data=OPC);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From the above plot, it looks like most customers have fewer than 1000 orders. Let's remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#OPC.sort_values('InvoiceNo',ascending=False)\n",
    "\n",
    "Outliers = OPC[OPC['InvoiceNo'] > 1000].CustomerID.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(DIPC.Quantity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = sns.distplot(OPC.InvoiceNo,bins=1000)\n",
    "plt.xlim(0,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Plotting total amount per order per week\n",
    "\n",
    "data = OR.loc[:,['Week','Total Amount']]\n",
    "data.sort_values('Week',inplace=True)\n",
    "data.set_index('Week',inplace=True) \n",
    "\n",
    "\n",
    "data['Total Amount'].plot(figsize=(16, 12))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Plotting number of orders per weekday\n",
    "\n",
    "data = pd.DataFrame(OR.groupby(['D_O_W'])['InvoiceNo'].nunique()).reset_index()\n",
    "\n",
    "data.sort_values('D_O_W',inplace=True)\n",
    "\n",
    "data.set_index('D_O_W',inplace=True) \n",
    "\n",
    "data['InvoiceNo'].plot(figsize=(16, 12))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Plotting number of orders per week\n",
    "\n",
    "data = pd.DataFrame(OR.groupby(['Week'])['InvoiceNo'].nunique()).reset_index()\n",
    "\n",
    "data.sort_values('Week',inplace=True)\n",
    "\n",
    "data.set_index('Week',inplace=True) \n",
    "\n",
    "data['InvoiceNo'].plot(figsize=(16, 12))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec\n",
    "\n",
    "### https://machinelearningmastery.com/develop-word-embeddings-python-gensim/\n",
    "\n",
    "### https://blog.manash.me/how-to-use-pre-trained-word-vectors-from-facebooks-fasttext-a71e6d55f27\n",
    "\n",
    "### http://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "filename = 'GoogleNews-vectors-negative300.bin'\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=True)\n",
    "\n",
    "# calculate: (king - man) + woman = ?\n",
    "result = model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
    "print(result)\n",
    "\n",
    "# Pick a word \n",
    "find_similar_to = 'Hogwarts'\n",
    "\n",
    "# Finding out similar words [default= top 10]\n",
    "for similar_word in model.similar_by_word(find_similar_to):\n",
    "    print(similar_word[0], similar_word[1])\n",
    "\n",
    "\n",
    "# Pick a word \n",
    "find_similar_to = 'pain'\n",
    "\n",
    "# Finding out similar words [default= top 10]\n",
    "for similar_word in model.similar_by_word(find_similar_to):\n",
    "    print(similar_word[0], similar_word[1])\n",
    "\n",
    "\n",
    "# Pick a word \n",
    "find_similar_to = 'obama'\n",
    "\n",
    "# Finding out similar words [default= top 10]\n",
    "for similar_word in model.similar_by_word(find_similar_to):\n",
    "    print(\"Related word: {0}  ,Similarity: {1:.2f}\".format(\n",
    "        similar_word[0], similar_word[1]\n",
    "    ))\n",
    "\n",
    "# Getting the tokens \n",
    "words = []\n",
    "for word in model.vocab:\n",
    "    words.append(word)\n",
    "\n",
    "    \n",
    "# Printing out number of tokens available\n",
    "print(\"Number of Tokens: {}\".format(len(words)))\n",
    "\n",
    "# Printing out the dimension of a word vector \n",
    "print(\"Dimension of a word vector: {}\".format(\n",
    "    len(model[words[0]])\n",
    "))\n",
    "\n",
    "\n",
    "\n",
    "# # Print out the vector of a word \n",
    "# print(\"Vector components of a word: {}\".format(\n",
    "#     model[words[0]]\n",
    "# ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Load in GloVe files by first changing current directory\n",
    "os.chdir('/Users/zacklarsen/Dropbox/Inference Analytics Team Folder/Zack Work/Glove.6B/')\n",
    "#!ls\n",
    "\n",
    "\n",
    "\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove_input_file = 'glove.6B.300d.txt'\n",
    "word2vec_output_file = 'glove.6B.300d.txt.word2vec'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)\n",
    "\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "# load the Stanford GloVe model\n",
    "filename = 'glove.6B.300d.txt.word2vec'\n",
    "Glove_model = KeyedVectors.load_word2vec_format(filename, binary=False)\n",
    "\n",
    "## Reset current directory\n",
    "os.chdir('/Users/zacklarsen/Dropbox/Inference Analytics Team Folder/Zack Work')\n",
    "\n",
    "# Pick a word \n",
    "find_similar_to = 'obama'\n",
    "\n",
    "# Finding out similar words [default= top 10]\n",
    "for similar_word in Glove_model.similar_by_word(find_similar_to):\n",
    "    print(similar_word[0], similar_word[1])\n",
    "\n",
    "\n",
    "# Pick a word \n",
    "find_similar_to = 'trump'\n",
    "\n",
    "# Finding out similar words [default= top 10]\n",
    "for similar_word in Glove_model.similar_by_word(find_similar_to):\n",
    "    print(similar_word[0], similar_word[1])\n",
    "\n",
    "\n",
    "# Pick a word \n",
    "find_similar_to = 'wiki'\n",
    "\n",
    "# Finding out similar words [default= top 10]\n",
    "for similar_word in Glove_model.similar_by_word(find_similar_to):\n",
    "    print(similar_word[0], similar_word[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in larger GloVe crawled from web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Load in GloVe files by first changing current directory\n",
    "os.chdir('/Users/zacklarsen/Dropbox/Inference Analytics Team Folder/Zack Work/')\n",
    "#!ls\n",
    "\n",
    "\n",
    "\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove_input_file = 'glove.840B.300d.txt'\n",
    "word2vec_output_file = 'glove.840B.300d.txt.word2vec'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)\n",
    "\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "# load the Stanford GloVe model\n",
    "filename = 'glove.840B.300d.txt.word2vec'\n",
    "Glove_model = KeyedVectors.load_word2vec_format(filename, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
